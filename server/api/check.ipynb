{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import PIL\n",
    "import requests\n",
    "import io\n",
    "import matplotlib\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import pathlib\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import json\n",
    "import re\n",
    "\n",
    "keras.config.set_floatx(\"bfloat16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyDLdORNkYX-Xy_DwgrAUetBsDzgaKR1pTw\")\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = {\n",
    "    'mime_type': 'image/jpeg',\n",
    "    'data': pathlib.Path('pngtree-young-man-binging-on-beer-restaurant-alcoholic-drunk-photo-image_2785389.jpg').read_bytes()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "{\n",
    "  \"tasks\": [\n",
    "    {\n",
    "      \"task_id\": 1,\n",
    "      \"description\": \"Determine the number of people drinking Heineken beers in the image.\",\n",
    "      \"output\": \"people_drink_message\"\n",
    "    },\n",
    "    {\n",
    "      \"task_id\": 2,\n",
    "      \"description\": \"Analyze the mood and tone of the image. Possible options: [Happy, Angry, Enjoyable, Relaxed, Neutral].\",\n",
    "      \"output\": \"mood_message\"\n",
    "    },\n",
    "    {\n",
    "      \"task_id\": 3,\n",
    "      \"description\": \"Count the number of marketing staff present in the image.\",\n",
    "      \"output\": \"number_of_marketing_staff_message\"\n",
    "    },\n",
    "    {\n",
    "      \"task_id\": 4,\n",
    "      \"description\": \"Identify the location of the scene. Possible options: [bar, pub, restaurant, grocery store, supermarket, party, celebration, gathering, happy hour, fun time].\",\n",
    "      \"output\": \"location_message\"\n",
    "    },\n",
    "    {\n",
    "      \"task_id\": 5,\n",
    "      \"description\": \"Provide an array of JSON bounding boxes for detected objects. Include people drinking and staff, location. The structure should be as follows:\",\n",
    "      \"output\": \"bounding_boxes\",\n",
    "      \"format\": \"json\",\n",
    "      \"structure\": [\n",
    "        {\n",
    "          \"object\": \"people_drinking\",\n",
    "          \"bounding_box\": {\n",
    "            \"xmin\": 0,\n",
    "            \"xmax\": 0,\n",
    "            \"ymin\": 0,\n",
    "            \"ymax\": 0\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"object\": \"staff\",\n",
    "          \"bounding_box\": {\n",
    "            \"xmin\": 0,\n",
    "            \"xmax\": 0,\n",
    "            \"ymin\": 0,\n",
    "            \"ymax\": 0\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"instructions\": \"If the scene does not contain the elements requested, please state that there are no such things in the photo.\"\n",
    "}\n",
    "\"\"\"\n",
    "response = model.generate_content([image, prompt])\n",
    "text = response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response):\n",
    "    \"\"\"\n",
    "    Làm sạch phần ghi chú hoặc các câu tiếng Anh không mong muốn trong phản hồi.\n",
    "    \"\"\"\n",
    "    lines = response.split(\"\\n\")\n",
    "    cleaned_lines = [line for line in lines if not line.startswith(\"Note:\") and \"apologized\" not in line]\n",
    "    cleaned_lines = [line for line in cleaned_lines if not (line.startswith(\"(Tiếng Anh\") or \"We are\" in line or \"Note:\" in line)]\n",
    "    return \"\".join(cleaned_lines).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \"tasks\": [    {      \"task_id\": 1,      \"description\": \"Determine the number of people drinking Heineken beers in the image.\",      \"output\": \"I cannot confirm if the person is drinking a Heineken beer, as there is no logo visible in the image.\"    },    {      \"task_id\": 2,      \"description\": \"Analyze the mood and tone of the image. Possible options: [Happy, Angry, Enjoyable, Relaxed, Neutral].\",      \"output\": \"mood_message: The mood and tone of the image appear to be **Relaxed** or **Enjoyable**.\"    },    {      \"task_id\": 3,      \"description\": \"Count the number of marketing staff present in the image.\",      \"output\": \"number_of_marketing_staff_message: There are no marketing staff visible in the image.\"    },    {      \"task_id\": 4,      \"description\": \"Identify the location of the scene. Possible options: [bar, pub, restaurant, grocery store, supermarket, party, celebration, gathering, happy hour, fun time].\",      \"output\": \"location_message: The location appears to be a **bar** or **pub**, judging by the brick wall and window reflection.\"    },    {      \"task_id\": 5,      \"description\": \"Provide an array of JSON bounding boxes for detected objects. Include people drinking and staff, location. The structure should be as follows:\",      \"output\": \"bounding_boxes: [{\\\"object\\\": \\\"people_drinking\\\", \\\"bounding_box\\\": {\\\"xmin\\\": 14, \\\"xmax\\\": 999, \\\"ymin\\\": 11, \\\"ymax\\\": 998}}],\\nThere are no staff members visible in the provided image.\",      \"format\": \"json\"    }  ]}\n"
     ]
    }
   ],
   "source": [
    "print(clean_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new workbook: example.xlsx\n",
      "Saved data to example.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import PIL\n",
    "import requests\n",
    "import io\n",
    "import matplotlib\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import pathlib\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import json\n",
    "import re\n",
    "\n",
    "keras.config.set_floatx(\"bfloat16\")\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDLdORNkYX-Xy_DwgrAUetBsDzgaKR1pTw\")\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "\n",
    "def clean_response(response):\n",
    "    \"\"\"\n",
    "    Làm sạch phần ghi chú hoặc các câu tiếng Anh không mong muốn trong phản hồi.\n",
    "    \"\"\"\n",
    "    lines = response.split(\"\\n\")\n",
    "    cleaned_lines = [line for line in lines if not line.startswith(\"Note:\") and \"apologized\" not in line]\n",
    "    cleaned_lines = [line for line in cleaned_lines if not (line.startswith(\"(Tiếng Anh\") or \"We are\" in line or \"Note:\" in line)]\n",
    "    return \"\".join(cleaned_lines).strip()\n",
    "\n",
    "def process_question(file_paths, number_img):\n",
    "    image = {\n",
    "    'mime_type': 'image/jpeg',\n",
    "    'data': pathlib.Path(f'{file_paths[number_img]}').read_bytes()\n",
    "    }\n",
    "    prompt = \"\"\"\n",
    "    {\n",
    "    \"tasks\": [\n",
    "        {\n",
    "        \"task_id\": 1,\n",
    "        \"description\": \"Determine the number of people drinking Heineken beers in the image.\",\n",
    "        \"output\": \"people_drink_message\"\n",
    "        },\n",
    "        {\n",
    "        \"task_id\": 2,\n",
    "        \"description\": \"Analyze the mood and tone of the image. Possible options: [Happy, Angry, Enjoyable, Relaxed, Neutral].\",\n",
    "        \"output\": \"mood_message\"\n",
    "        },\n",
    "        {\n",
    "        \"task_id\": 3,\n",
    "        \"description\": \"Count the number of marketing staff present in the image.\",\n",
    "        \"output\": \"number_of_marketing_staff_message\"\n",
    "        },\n",
    "        {\n",
    "        \"task_id\": 4,\n",
    "        \"description\": \"Identify the location of the scene. Possible options: [bar, pub, restaurant, grocery store, supermarket, party, celebration, gathering, happy hour, fun time].\",\n",
    "        \"output\": \"location_message\"\n",
    "        },\n",
    "        {\n",
    "        \"task_id\": 5,\n",
    "        \"description\": \"Provide an array of JSON bounding boxes for detected objects. Include people drinking and staff, location. The structure should be as follows:\",\n",
    "        \"output\": \"bounding_boxes\",\n",
    "        \"format\": \"json\",\n",
    "        \"structure\": [\n",
    "            {\n",
    "            \"object\": \"people_drinking\",\n",
    "            \"bounding_box\": {\n",
    "                \"xmin\": 0,\n",
    "                \"xmax\": 0,\n",
    "                \"ymin\": 0,\n",
    "                \"ymax\": 0\n",
    "            }\n",
    "            },\n",
    "            {\n",
    "            \"object\": \"staff\",\n",
    "            \"bounding_box\": {\n",
    "                \"xmin\": 0,\n",
    "                \"xmax\": 0,\n",
    "                \"ymin\": 0,\n",
    "                \"ymax\": 0\n",
    "            }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    \"instructions\": \"If the scene does not contain the elements requested, please state that there are no such things in the photo.\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = model.generate_content([image, prompt])\n",
    "    answer = clean_response(response.text)\n",
    "    json_file  = json.loads(answer)\n",
    "    return json_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads/he.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'uploads/he.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m number_img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(file_paths)):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file_paths[number_img])\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     text\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "Cell \u001b[0;32mIn[31], line 36\u001b[0m, in \u001b[0;36mprocess_question\u001b[0;34m(file_paths, number_img)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_question\u001b[39m(file_paths, number_img):\n\u001b[1;32m     34\u001b[0m     image \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmime_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage/jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumber_img\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     }\n\u001b[1;32m     38\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124m    }\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content([image, prompt])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aio2024_env/lib/python3.12/pathlib.py:1019\u001b[0m, in \u001b[0;36mPath.read_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m    Open the file in bytes mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1019\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/aio2024_env/lib/python3.12/pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1012\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'uploads/he.jpg'"
     ]
    }
   ],
   "source": [
    "file_paths = ['uploads/he.jpg', 'uploads/hi.png']\n",
    "\n",
    "text = []\n",
    "for number_img in range(len(file_paths)):\n",
    "    print(file_paths[number_img])\n",
    "    result = process_question(file_paths, number_img)\n",
    "    text.append(result)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tạo file 'product_status.xlsx' mới...\n",
      "Đã lưu dữ liệu vào file 'product_status.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Tên file Excel\n",
    "excel_file = 'product_status.xlsx'\n",
    "list_files = ['image_predict_1.png', 'image_predict_5.png']\n",
    "\n",
    "\n",
    "for i in range(len(list_files)):\n",
    "    \n",
    "\n",
    "\n",
    "# Tên các cột và dữ liệu\n",
    "data = [\n",
    "    ('image_predict_1.png', 'yes', 'có nhiều sản phẩm'),\n",
    "    ('image_predict_5.png', 'no', 'không có nhiều sản phẩm')\n",
    "]\n",
    "\n",
    "try:\n",
    "    wb = openpyxl.load_workbook(excel_file)\n",
    "    ws = wb.active\n",
    "    print(f\"File '{excel_file}' đã tồn tại. Đang cập nhật...\")\n",
    "except FileNotFoundError:\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(['image_path', 'status_exist_heneiken', 'chat_description'])\n",
    "    print(f\"Tạo file '{excel_file}' mới...\")\n",
    "for row_data in data:\n",
    "    ws.append(row_data)\n",
    "wb.save(excel_file)\n",
    "print(f\"Đã lưu dữ liệu vào file '{excel_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
